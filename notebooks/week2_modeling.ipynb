{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c470ceb4",
   "metadata": {},
   "source": [
    "Initial and create copy of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f69c5cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18943 entries, 0 to 18942\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   player_url               18943 non-null  object \n",
      " 1   dob                      18943 non-null  object \n",
      " 2   overall                  18943 non-null  int64  \n",
      " 3   potential                18943 non-null  int64  \n",
      " 4   value_eur                18943 non-null  int64  \n",
      " 5   real_face                18943 non-null  bool   \n",
      " 6   joined                   17960 non-null  object \n",
      " 7   passing                  16860 non-null  float64\n",
      " 8   dribbling                16860 non-null  float64\n",
      " 9   attacking_short_passing  18943 non-null  int64  \n",
      " 10  movement_reactions       18943 non-null  int64  \n",
      " 11  mentality_composure      18943 non-null  int64  \n",
      " 12  lcm                      18943 non-null  int64  \n",
      "dtypes: bool(1), float64(2), int64(7), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "data = pd.read_csv(\"/home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/cleaned/fifa_target_leakage_cleaned.csv\")\n",
    "fifa = data.copy()\n",
    "fifa.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052ee8a",
   "metadata": {},
   "source": [
    "Encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8bfbb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENCODING CATEGORICAL VARIABLES FOR FIFA ===\n",
      "Initial data shape: (18943, 13)\n",
      " Created calculated_age from dob\n",
      " Created years_since_joined from joined\n",
      "üóëÔ∏è  Removed player_url\n",
      "\n",
      " FINAL SUMMARY:\n",
      "   ‚Ä¢ Final data shape: (18943, 18)\n",
      "   ‚Ä¢ Total new features created: 8\n",
      "üíæ Encoded data saved to: /home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_encoded.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categorical_variables_fifa(data, target_column='value_eur'):\n",
    "    \"\"\"\n",
    "    Encode categorical variables for FIFA regression project\n",
    "    Adapted for predicting value_eur\n",
    "    \"\"\"\n",
    "    print(\"=== ENCODING CATEGORICAL VARIABLES FOR FIFA ===\")\n",
    "    print(f\"Initial data shape: {data.shape}\")\n",
    "    \n",
    "    data = data.copy()\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Identify categorical columns (excluding target)\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Remove target variable if present\n",
    "    if target_column in categorical_columns:\n",
    "        categorical_columns.remove(target_column)\n",
    "    \n",
    "    # Classify columns based on their type and content\n",
    "    special_columns = []\n",
    "    binary_categorical = []\n",
    "    onehot_categorical = []\n",
    "    date_columns = []\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in data.columns:\n",
    "            unique_count = data[col].nunique()\n",
    "            \n",
    "            # Check for date columns\n",
    "            if col in ['dob', 'joined'] or 'date' in col.lower():\n",
    "                date_columns.append(col)\n",
    "            \n",
    "            # Check for URL columns (high cardinality, not useful)\n",
    "                special_columns.append(col)\n",
    "            \n",
    "            # Binary categorical \n",
    "            elif unique_count == 2:\n",
    "                binary_categorical.append(col)\n",
    "            \n",
    "            # Small categorical \n",
    "            elif unique_count <= 10:\n",
    "                onehot_categorical.append(col)\n",
    "            \n",
    "            # Large categorical \n",
    "            else:\n",
    "                if unique_count <= 50:\n",
    "                    onehot_categorical.append(col)\n",
    "                else:\n",
    "                    special_columns.append(col)\n",
    "    \n",
    "    # HANDLE DATE COLUMNS\n",
    "    for col in date_columns:\n",
    "        if col in data.columns:\n",
    "            # Convert to datetime\n",
    "            data[col + '_datetime'] = pd.to_datetime(data[col], errors='coerce')\n",
    "            \n",
    "            # Extract useful features\n",
    "            data[col + '_year'] = data[col + '_datetime'].dt.year\n",
    "            data[col + '_month'] = data[col + '_datetime'].dt.month\n",
    "            data[col + '_day_of_year'] = data[col + '_datetime'].dt.dayofyear\n",
    "            \n",
    "            # Calculate age for dob\n",
    "            if col == 'dob':\n",
    "                current_year = 2025\n",
    "                data['calculated_age'] = current_year - data[col + '_year']\n",
    "                print(f\" Created calculated_age from {col}\")\n",
    "            \n",
    "            # Calculate years since joining\n",
    "            if col == 'joined':\n",
    "                current_year = 2025\n",
    "                data['years_since_joined'] = current_year - data[col + '_year']\n",
    "                print(f\" Created years_since_joined from {col}\")\n",
    "            \n",
    "            # Remove original columns\n",
    "            data = data.drop(columns=[col, col + '_datetime'])\n",
    "    \n",
    "    # REMOVE SPECIAL COLUMNS\n",
    "    for col in special_columns:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns=[col])\n",
    "            print(f\"üóëÔ∏è  Removed {col}\")\n",
    "    \n",
    "    # LABEL ENCODING FOR BINARY CATEGORICAL\n",
    "    for col in binary_categorical:\n",
    "        if col in data.columns:\n",
    "            le = LabelEncoder()\n",
    "            col_values = data[col].astype(str)\n",
    "            data[col] = le.fit_transform(col_values)\n",
    "            label_encoders[col] = le\n",
    "            \n",
    "            encoding_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            print(f\" Label encoded {col}: {encoding_map}\")\n",
    "    \n",
    "    # ONE-HOT ENCODING FOR MULTI-CLASS CATEGORICAL\n",
    "    created_dummies = []\n",
    "    \n",
    "    for col in onehot_categorical:\n",
    "        if col in data.columns:\n",
    "            dummies = pd.get_dummies(data[col], prefix=col, drop_first=True, dummy_na=True)\n",
    "            created_dummies.extend(dummies.columns.tolist())\n",
    "            \n",
    "            data = pd.concat([data, dummies], axis=1)\n",
    "            print(f\" One-hot encoded {col}: created {len(dummies.columns)} dummy variables\")\n",
    "    \n",
    "    # Remove original categorical columns after one-hot encoding\n",
    "    for col in onehot_categorical:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns=[col])\n",
    "    \n",
    "    print(\"\\n FINAL SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Final data shape: {data.shape}\")\n",
    "    print(f\"   ‚Ä¢ Total new features created: {len(created_dummies) + len(date_columns)*4}\")\n",
    "    \n",
    "    output_path = '/home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_encoded.csv'\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Encoded data saved to: {output_path}\")\n",
    "    \n",
    "    return data, label_encoders\n",
    "\n",
    "\n",
    "fifa_encoded, encoders = encode_categorical_variables_fifa(fifa, target_column='value_eur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d11bff",
   "metadata": {},
   "source": [
    "MODEL CRAFTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88486bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIFA REGRESSION MODEL ===\n",
      "üìÅ Loaded data from: /home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_encoded.csv\n",
      "üìä Data shape: (18943, 18)\n",
      " Target: value_eur\n",
      " Features: 17 columns\n",
      " Target stats: Min=0, Max=4,050,000, Mean=1,265,326\n",
      " Train set: 15154 samples\n",
      " Test set: 3789 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Linear Regression...\n",
      " Linear Regression Results:\n",
      "   R¬≤ Score: 0.7589\n",
      "   RMSE: ‚Ç¨664,627\n",
      "   MAE: ‚Ç¨532,395\n",
      "\n",
      " Training Random Forest...\n",
      " Random Forest Results:\n",
      "   R¬≤ Score: 0.9663\n",
      "   RMSE: ‚Ç¨248,511\n",
      "   MAE: ‚Ç¨69,783\n",
      "\n",
      " MODEL COMPARISON:\n",
      " Best Model: Random Forest (R¬≤ = 0.9663)\n",
      "\n",
      " TOP 10 MOST IMPORTANT FEATURES:\n",
      "    1. overall                   0.8604\n",
      "    2. potential                 0.0703\n",
      "    3. dob_year                  0.0180\n",
      "    4. calculated_age            0.0178\n",
      "    5. joined_month              0.0054\n",
      "    6. joined_day_of_year        0.0053\n",
      "    7. dribbling                 0.0040\n",
      "    8. movement_reactions        0.0037\n",
      "    9. mentality_composure       0.0033\n",
      "   10. lcm                       0.0027\n",
      "\n",
      " SAMPLE PREDICTIONS vs ACTUAL:\n",
      "   1. Actual: ‚Ç¨  230,000 | Predicted: ‚Ç¨  250,350 | Error:   8.8%\n",
      "   2. Actual: ‚Ç¨1,000,000 | Predicted: ‚Ç¨  980,500 | Error:   1.9%\n",
      "   3. Actual: ‚Ç¨1,200,000 | Predicted: ‚Ç¨1,203,000 | Error:   0.2%\n",
      "   4. Actual: ‚Ç¨4,050,000 | Predicted: ‚Ç¨4,050,000 | Error:   0.0%\n",
      "   5. Actual: ‚Ç¨2,300,000 | Predicted: ‚Ç¨2,235,000 | Error:   2.8%\n",
      "\n",
      "üíæ Results saved to: /home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_regression_results.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def simple_fifa_regression(data_path=None, data=None, target_column='value_eur'):\n",
    "    \"\"\"\n",
    "    Simple regression model for FIFA player value prediction\n",
    "    \"\"\"\n",
    "    print(\"=== FIFA REGRESSION MODEL ===\")\n",
    "    \n",
    "    # Load data\n",
    "    if data is None:\n",
    "        if data_path is None:\n",
    "            data_path = '/home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_encoded.csv'\n",
    "        data = pd.read_csv(data_path)\n",
    "        print(f\" Loaded data from: {data_path}\")\n",
    "    \n",
    "    print(f\" Data shape: {data.shape}\")\n",
    "    \n",
    "    # Prepare features and target\n",
    "    if target_column not in data.columns:\n",
    "        print(f\" Error: Target column '{target_column}' not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    print(f\" Target: {target_column}\")\n",
    "    print(f\" Features: {X.shape[1]} columns\")\n",
    "    print(f\" Target stats: Min={y.min():,.0f}, Max={y.max():,.0f}, Mean={y.mean():,.0f}\")\n",
    "    \n",
    "    # Handle any remaining missing values\n",
    "    X = X.fillna(X.mean())\n",
    "    y = y.fillna(y.mean())\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\" Train set: {X_train.shape[0]} samples\")\n",
    "    print(f\" Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Scale features for Linear Regression\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Model 1: Linear Regression\n",
    "    print(\"\\n Training Linear Regression...\")\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate Linear Regression\n",
    "    lr_r2 = r2_score(y_test, y_pred_lr)\n",
    "    lr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "    lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "    \n",
    "    print(\" Linear Regression Results:\")\n",
    "    print(f\"   R¬≤ Score: {lr_r2:.4f}\")\n",
    "    print(f\"   RMSE: ‚Ç¨{lr_rmse:,.0f}\")\n",
    "    print(f\"   MAE: ‚Ç¨{lr_mae:,.0f}\")\n",
    "    \n",
    "    # Model 2: Random Forest (doesn't need scaling)\n",
    "    print(\"\\n Training Random Forest...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Random Forest\n",
    "    rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "    rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "    \n",
    "    print(\" Random Forest Results:\")\n",
    "    print(f\"   R¬≤ Score: {rf_r2:.4f}\")\n",
    "    print(f\"   RMSE: ‚Ç¨{rf_rmse:,.0f}\")\n",
    "    print(f\"   MAE: ‚Ç¨{rf_mae:,.0f}\")\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\n MODEL COMPARISON:\")\n",
    "    if rf_r2 > lr_r2:\n",
    "        print(f\" Best Model: Random Forest (R¬≤ = {rf_r2:.4f})\")\n",
    "        best_predictions = y_pred_rf\n",
    "        best_name = \"Random Forest\"\n",
    "    else:\n",
    "        print(f\" Best Model: Linear Regression (R¬≤ = {lr_r2:.4f})\")\n",
    "        best_predictions = y_pred_lr\n",
    "        best_name = \"Linear Regression\"\n",
    "    \n",
    "    # Feature importance (Random Forest only)\n",
    "    if hasattr(rf_model, 'feature_importances_'):\n",
    "        print(\"\\n TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': rf_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "            print(f\"   {i+1:2d}. {row['feature']:<25} {row['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\n SAMPLE PREDICTIONS vs ACTUAL:\")\n",
    "    sample_indices = np.random.choice(len(y_test), 5, replace=False)\n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        actual = y_test.iloc[idx]\n",
    "        predicted = best_predictions[idx]\n",
    "        error = abs(actual - predicted)\n",
    "        error_pct = (error / actual) * 100 if actual > 0 else 0\n",
    "        \n",
    "        print(f\"   {i+1}. Actual: ‚Ç¨{actual:>9,.0f} | Predicted: ‚Ç¨{predicted:>9,.0f} | Error: {error_pct:5.1f}%\")\n",
    "    \n",
    "    # Save results\n",
    "    results_path = '/home/antonios/Desktop/Practica_de_vara/data-science-internship2/data/results/fifa_regression_results.txt'\n",
    "    with open(results_path, 'w') as f:\n",
    "        f.write(\"FIFA Player Value Prediction Results\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\\n\")\n",
    "        f.write(f\"Dataset: {data.shape[0]} players, {X.shape[1]} features\\n\\n\")\n",
    "        f.write(\"Linear Regression:\\n\")\n",
    "        f.write(f\"  R¬≤ Score: {lr_r2:.4f}\\n\")\n",
    "        f.write(f\"  RMSE: ‚Ç¨{lr_rmse:,.0f}\\n\")\n",
    "        f.write(f\"  MAE: ‚Ç¨{lr_mae:,.0f}\\n\\n\")\n",
    "        f.write(\"Random Forest:\\n\")\n",
    "        f.write(f\"  R¬≤ Score: {rf_r2:.4f}\\n\")\n",
    "        f.write(f\"  RMSE: ‚Ç¨{rf_rmse:,.0f}\\n\")\n",
    "        f.write(f\"  MAE: ‚Ç¨{rf_mae:,.0f}\\n\\n\")\n",
    "        f.write(f\"Best Model: {best_name}\\n\")\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved to: {results_path}\")\n",
    "    \n",
    "    return {\n",
    "        'linear_regression': {\n",
    "            'model': lr_model,\n",
    "            'scaler': scaler,\n",
    "            'r2': lr_r2,\n",
    "            'rmse': lr_rmse,\n",
    "            'mae': lr_mae\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': rf_model,\n",
    "            'r2': rf_r2,\n",
    "            'rmse': rf_rmse,\n",
    "            'mae': rf_mae\n",
    "        },\n",
    "        'test_data': (X_test, y_test),\n",
    "        'feature_names': X.columns.tolist()\n",
    "    }\n",
    "\n",
    "\n",
    "results = simple_fifa_regression()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
